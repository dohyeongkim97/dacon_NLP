{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86191b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "86e167b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f13de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Temp\\ipykernel_20964\\82325636.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fa4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9c564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99eba828",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b3c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_set(df: pd.DataFrame):\n",
    "    if 'ID' in df.columns:\n",
    "        global dfID\n",
    "        dfID = df['ID']\n",
    "        df.drop(columns = 'ID', inplace=True)\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        if 'first_party' in df.columns and 'second_party' in df.columns:\n",
    "            if df.loc[i, 'first_party'] == 'United States' or df.loc[i, 'second_party'] == 'United_States':\n",
    "                df.loc[i, 'US'] = 1\n",
    "            else:\n",
    "                df.loc[i, 'US'] = 0\n",
    "\n",
    "    if 'first_party' in df.columns:\n",
    "        global dffp\n",
    "        dffp = df['first_party']\n",
    "        df.drop(columns = 'first_party', inplace=True)\n",
    "    if 'second_party' in df.columns:\n",
    "        global dfsp\n",
    "        dfsp = df['second_party']\n",
    "        df.drop(columns = 'second_party', inplace=True)\n",
    "        \n",
    "    \n",
    "    if 'first_party_winner' in df.columns:\n",
    "        global target\n",
    "        target = df['first_party_winner']\n",
    "        df.drop(columns = 'first_party_winner', inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb013fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_set(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335f4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vtr(data):\n",
    "    stw = set(stopwords.words('english'))\n",
    "    \n",
    "#     n = re.compile(\"^[a-zA-Z]\")\n",
    "    num = re.compile(\"\\d\")\n",
    "    for i in range(len(data)):\n",
    "        text = re.sub(num, ' ', data.loc[i, 'facts'].lower())\n",
    "        words = wt(text)\n",
    "        \n",
    "        texts = []\n",
    "        for j in words:\n",
    "            if j not in stw:\n",
    "                    texts.append(j)\n",
    "            \n",
    "            try:\n",
    "                int(j)\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                texts.append(j)\n",
    "                \n",
    "            finally:\n",
    "                continue\n",
    "                \n",
    "        phrase = \" \".join(texts)\n",
    "        phrase = phrase.replace(',', '')\n",
    "        data.loc[i, 'facts'] = phrase\n",
    "        \n",
    "    min_df = 5\n",
    "    max_features = 1500\n",
    "    \n",
    "    if 'tf' not in globals():\n",
    "\n",
    "        global tf\n",
    "        tf = TfidfVectorizer(min_df = min_df, max_features = max_features)\n",
    "        \n",
    "    if 'vct' not in globals():\n",
    "        global vct\n",
    "        vct = tf.fit_transform(data['facts'])\n",
    "    else:\n",
    "        global vcttest\n",
    "        vcttest = tf.transform(data['facts'])\n",
    "    \n",
    "    if 'feature_names' not in globals():\n",
    "        global feature_names\n",
    "        feature_names = tf.get_feature_names_out()\n",
    "    \n",
    "    if 'vctdf' not in globals():\n",
    "        global vctdf \n",
    "        vctdf = pd.DataFrame(vct.toarray(), columns=feature_names)\n",
    "        vctdf = pd.concat([vctdf, data['US']], axis=1)\n",
    "    \n",
    "    else:\n",
    "        global vctdft\n",
    "        vctdft = pd.DataFrame(vcttest.toarray(), columns=feature_names)\n",
    "        vctdft = pd.concat([vctdft, data['US']], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78cd3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "submis = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394484b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_set(test)\n",
    "vtr(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2cee7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = submis['ID']\n",
    "submis.drop(columns = 'ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "133b070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data=None, target=None, submission_data = None, submission_target=None):\n",
    "    \n",
    "    \n",
    "    \n",
    "    xtr, xte, ytr, yte = train_test_split(data, target)\n",
    "    \n",
    "    \n",
    "#     params_grid_rfc = {\n",
    "#         'min_samples_leaf': [2, 3, 5, 7],\n",
    "#         'n_estimators': [3, 5, 7, 9, 10, 11, 12, 15]\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     global rfc, grid_search_rfc\n",
    "#     rfc = RandomForestClassifier()\n",
    "#     grid_search_rfc = GridSearchCV(rfc, param_grid = params_grid_rfc)\n",
    "#     grid_search_rfc.fit(xtr, ytr)\n",
    "#     grid_search_rfc.score(xtr, ytr)\n",
    "\n",
    "#     rfctr = grid_search_rfc.best_estimator_.predict(xtr)\n",
    "#     rfcte = grid_search_rfc.best_estimator_.predict(xte)\n",
    "\n",
    "#     best_params_rfc = 'min_samples_leaf':7, 'n_estimators':15\n",
    "#     best_params_xgb = {'learning_rate' = 0.03, 'max_depth'= 3, 'min_child_weight'=5, 'scale_pos_weight'=2}\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "#     xgbmodel = XGBClassifier(params = {'learning_rate' : 0.03, \n",
    "#                          'max_depth' : 3, \n",
    "#                          'min_child_weight' : 5, \n",
    "#                          'scale_pos_weight' : 2})\n",
    "    \n",
    "#     print(\"gridsearch_rfc best_params_ :\", grid_search_rfc.best_params_)\n",
    "\n",
    "    rfc.fit(xtr, ytr)\n",
    "    rfctr = rfc.predict(xtr)\n",
    "    print('rfc, train')\n",
    "    print(accuracy_score(rfctr, ytr))\n",
    "\n",
    "    rfcte = rfc.predict(xte)\n",
    "    print('rfc, test')\n",
    "    print(accuracy_score(rfcte, yte))\n",
    "\n",
    "    global rfcpred\n",
    "#     rfcpred = grid_search_rfc.best_estimator_.predict(submission_data)\n",
    "    rfcpred = pd.DataFrame(rfc.predict(submission_data))\n",
    "        \n",
    "#     global grid_search_xgb\n",
    "#     params_grid_xgb = {'max_depth': [3, 5, 7, 9, 10],\n",
    "#          'learning_rate' : [0.01, 0.03, 0.05, 0.1],\n",
    "#          'scale_pos_weight': [2],\n",
    "#          'min_child_weight': [2, 3, 5]}\n",
    "\n",
    "#     grid_search_xgb = GridSearchCV(XGBClassifier(), param_grid = params_grid_xgb, scoring='accuracy', cv=5)\n",
    "#     grid_search_xgb.fit(xtr, ytr)\n",
    "\n",
    "#     xgbtr = grid_search_xgb.best_estimator_.predict(xtr)\n",
    "#     xgbte = grid_search_xgb.best_estimator_.predict(xte)\n",
    "\n",
    "#     print('gridsearch_xgb best_params :', grid_search_xgb.best_params_)\n",
    "\n",
    "    xgbmodel = XGBClassifier(learning_rate = 0.03, max_depth= 3, min_child_weight= 5, scale_pos_weight= 2)\n",
    "    xgbmodel.fit(xtr, ytr)\n",
    "    \n",
    "    xgbtr = xgbmodel.predict(xtr)\n",
    "    print('xgb, train')\n",
    "    print(accuracy_score(xgbtr, ytr))\n",
    "\n",
    "    xgbte = xgbmodel.predict(xte)\n",
    "    print('xgb, test')\n",
    "    print(accuracy_score(xgbte, yte))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    global xgbpred\n",
    "#     xgbpred = grid_search_xgb.best_estimator_.predict(submission_data)\n",
    "    xgbpred = pd.DataFrame(xgbmodel.predict(submission_data))\n",
    "    \n",
    "    if 'ID' in submission_target.columns:\n",
    "        global subid\n",
    "        subid = submission_target['ID']\n",
    "        submission_target = submission_target.drop(columns = ['ID'])\n",
    "    \n",
    "    \n",
    "    gpcmodel = GaussianProcessClassifier(n_jobs = 150)\n",
    "    gpcmodel.fit(xtr, ytr)\n",
    "    \n",
    "    gpctr = gpcmodel.predict(xtr)\n",
    "    print('gpc, train')\n",
    "    print(accuracy_score(gpctr, ytr))\n",
    "    \n",
    "    gpcte = gpcmodel.predict(xte)\n",
    "    print('gpc, test')\n",
    "    print(accuracy_score(gpcte, yte))\n",
    "    \n",
    "    global gpcpred\n",
    "    gpcpred = pd.DataFrame(gpcmodel.predict(submission_data))\n",
    "    \n",
    "\n",
    "    global submission_xgb\n",
    "    submission_xgb = pd.concat([subid, xgbpred], axis=1)\n",
    "    \n",
    "    submission_xgb.columns = ['ID', 'first_party_winner']\n",
    "    \n",
    "    submission_xgb = submission_xgb.set_index(\"ID\")\n",
    "    \n",
    "    \n",
    "    global submission_rfc\n",
    "    submission_rfc = pd.concat([subid, rfcpred], axis=1)\n",
    "    \n",
    "    submission_rfc.columns = [\"ID\", 'first_party_winner']\n",
    "    \n",
    "    submission_rfc = submission_rfc.set_index('ID')\n",
    "    \n",
    "    global submission_gpc\n",
    "    submission_gpc = pd.concat([subid, gpcpred], axis=1)\n",
    "    submission_gpc.columns = ['ID', 'first_party_winner']\n",
    "    submissino_gpc = submission_gpc.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8e46e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, train\n",
      "0.9994617868675996\n",
      "rfc, test\n",
      "0.635483870967742\n",
      "xgb, train\n",
      "0.6722282023681377\n",
      "xgb, test\n",
      "0.646774193548387\n",
      "gpc, train\n",
      "0.6851453175457481\n",
      "gpc, test\n",
      "0.6483870967741936\n"
     ]
    }
   ],
   "source": [
    "train(vctdf, target, vctdft, submis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "045605d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_gpc.to_csv(\"{}gpc.csv\".format(datetime.today().strftime(\"%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cac1c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rfc.to_csv(\"{}rfc.csv\".format(datetime.today().strftime(\"%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122af2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_gpc.to_csv(\"{}gpc.csv\".format(datetime.today().strptime(\"%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "991cb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb.to_csv(\"{}xgb.csv\".format(datetime.today().strftime(\"%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "68201d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_classifier(data, target, subdata):\n",
    "    from sklearn.metrics.pairwise import linear_kernel\n",
    "    cosine_sim = linear_kernel(data, subdata)\n",
    "    cosine_sim = pd.DataFrame(cosine_sim)\n",
    "    \n",
    "\n",
    "    global answer\n",
    "    answer = []\n",
    "    \n",
    "    for i in range(len(cosine_sim.columns)):\n",
    "        m = max(cosine_train.loc[i, :])\n",
    "        for j in range(len(cosine_sim.index)):\n",
    "            if cosine_sim.loc[j, i] == m:\n",
    "                answer.append(target[j])\n",
    "                break\n",
    "                \n",
    "    answer = pd.DataFrame(answer)\n",
    "    \n",
    "    answer = pd.concat([subid, answer], axis=1)\n",
    "    \n",
    "    answer = answer.set_index(\"ID\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a425eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_classifier(vctdf, target, vctdft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0597363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.columns = ['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "49cf3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv(\"0703.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
